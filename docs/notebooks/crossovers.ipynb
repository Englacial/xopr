{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7e7209",
   "metadata": {},
   "source": [
    "---\n",
    "title: Crossover analysis\n",
    "description: Using xOPR to automatically find radar crossovers\n",
    "date: 2025-09-09\n",
    "---\n",
    "\n",
    "In this notebook, we demonstratate how to automatically find and analyze radar crossovers, both within and between campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.shapereader as shapereader\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.geometry\n",
    "import scipy.constants\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import xopr\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "hvplot.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28836ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.delayed as delayed\n",
    "from dask.distributed import LocalCluster\n",
    "\n",
    "client = LocalCluster().get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e44ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful projections\n",
    "epsg_3031 = ccrs.Stereographic(central_latitude=-90, true_scale_latitude=-71)\n",
    "latlng = ccrs.PlateCarree()\n",
    "features = gf.ocean.options(scale='50m').opts(projection=epsg_3031) * gf.coastline.options(scale='50m').opts(projection=epsg_3031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish an OPR session\n",
    "# You'll probably want to set a cache directory if you're running this locally to speed\n",
    "# up subsequent requests. You can do other things like customize the STAC API endpoint,\n",
    "# but you shouldn't need to do that for most use cases.\n",
    "opr = xopr.OPRConnection(cache_dir=\"radar_cache\")\n",
    "\n",
    "# Or you can open a connection without a cache directory (for example, if you're parallelizing\n",
    "# this on a cloud cluster without persistent storage).\n",
    "#opr = xopr.OPRConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252449c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = xopr.geometry.get_antarctic_regions(name=\"David\", merge_regions=True, simplify_tolerance=10000)\n",
    "region_projected = xopr.geometry.project_geojson(region, source_crs='EPSG:4326', target_crs=\"EPSG:3031\")\n",
    "\n",
    "region_hv = hv.Polygons([region_projected]).opts(\n",
    "    color='green',\n",
    "    line_color='black',\n",
    "    fill_alpha=0.5)\n",
    "\n",
    "(features * region_hv).opts(aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be63534",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_items_df = opr.query_frames(geometry=region)\n",
    "stac_items_df = stac_items_df.to_crs(epsg_3031)\n",
    "\n",
    "print(f\"Found {len(stac_items_df)} frames across {stac_items_df['collection'].nunique()} collections:\")\n",
    "stac_items_df.groupby('collection').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_lines = stac_items_df.hvplot(by='collection')\n",
    "(features * region_hv * flight_lines).opts(projection=epsg_3031, frame_width=500, aspect='equal', active_tools=['pan', 'wheel_zoom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fa14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitely room for improvement here, but the geopandas spatial join works pretty nicely for finding intersections between frames.\n",
    "# Couple thoughts:\n",
    "# 1. We might want to include a helper function for this\n",
    "# 2. This will not find self-intersections within a single frame.\n",
    "\n",
    "tmp_df = stac_items_df.reset_index()\n",
    "tmp_df['geom'] = tmp_df.geometry\n",
    "intersections = gpd.sjoin(tmp_df, tmp_df, how='inner', predicate='intersects', lsuffix='1', rsuffix='2')\n",
    "intersections = intersections[intersections['id_1'] != intersections['id_2']]\n",
    "intersections['intersection_geometry'] = intersections.apply(lambda row: row['geom_1'].intersection(row['geom_2']), axis=1)\n",
    "intersections.set_geometry('intersection_geometry', inplace=True, crs=stac_items_df.crs)\n",
    "intersections = intersections.drop_duplicates(subset=['intersection_geometry'])\n",
    "intersections = intersections.explode(index_parts=True).reset_index(drop=True)\n",
    "\n",
    "intersections_tmp = intersections[['id_1', 'id_2', 'intersection_geometry', 'collection_1', 'collection_2']].copy()\n",
    "\n",
    "for k in ['opr:date', 'opr:flight', 'opr:segment']:\n",
    "    intersections_tmp[f'{k}_1'] = intersections['properties_1'].apply(lambda x: x[k])\n",
    "    intersections_tmp[f'{k}_2'] = intersections['properties_2'].apply(lambda x: x[k])\n",
    "\n",
    "intersections = intersections_tmp\n",
    "\n",
    "filter_adjacent_frames = True\n",
    "if filter_adjacent_frames:\n",
    "    intersections = intersections[\n",
    "        (intersections['opr:date_1'] != intersections['opr:date_2']) |\n",
    "        (intersections['opr:flight_1'] != intersections['opr:flight_2']) |\n",
    "        ((intersections['opr:segment_1'] != (intersections['opr:segment_2'] + 1)) &\n",
    "         (intersections['opr:segment_1'] != (intersections['opr:segment_2'] - 1)))\n",
    "    ]\n",
    "\n",
    "print(f\"Found {len(intersections)} crossover points between flight lines.\")\n",
    "(features * region_hv * flight_lines * intersections.hvplot(label='Intersection Points', color='purple')).opts(frame_width=500, aspect='equal', active_tools=['pan', 'wheel_zoom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ad78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result of this is a GeoDataFrame where every column from the intersecting frames is preserved, with suffixes _1 and _2 to distinguish them.\n",
    "intersections.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94361c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def safe_get_layers_db(stac_item, opr=xopr.opr_access.OPRConnection()):\n",
    "    try:\n",
    "        retries = 10\n",
    "        backoff_time = 5\n",
    "        backoff_jitter = 30\n",
    "        while retries > 0:\n",
    "            try:\n",
    "                return opr.get_layers_db(stac_item)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                sleep_time = backoff_time + np.random.uniform(0, backoff_jitter)\n",
    "                print(f\"Request error fetching layers for {stac_item['id']}: {e}. Retrying in {sleep_time:.1f} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "                retries -= 1\n",
    "                backoff_time *= 2  # Exponential backoff\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching layers for {stac_item['id']}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_basal_layer_wgs84(stac_item, preloaded_layer=None, opr=xopr.opr_access.OPRConnection()):\n",
    "    if (preloaded_layer is None) or len(preloaded_layer) < 2:\n",
    "        layers = opr.get_layers_files(stac_item)\n",
    "    else:\n",
    "        layers = preloaded_layer\n",
    "    \n",
    "    basal_layer = layers[2]\n",
    "    surface_layer = layers[1]\n",
    "\n",
    "    surface_wgs84 = layers[1]['elev'] - (layers[1]['twtt'] * (scipy.constants.c / 2))\n",
    "    delta_twtt = basal_layer['twtt'] - surface_layer['twtt']\n",
    "    basal_wgs84 = surface_wgs84 - (delta_twtt * ((scipy.constants.c / np.sqrt(3.15)) / 2))\n",
    "\n",
    "    basal_layer['wgs84'] = basal_wgs84\n",
    "    return basal_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5119796",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def compute_crossover_error_impl(stac_item_1, stac_item_2, intersection_geometry, layer_1, layer_2):\n",
    "    \"\"\"Implementation that receives actual layer values\"\"\"\n",
    "    try:\n",
    "        bed_1 = get_basal_layer_wgs84(stac_item_1, preloaded_layer=layer_1).rename({'lat': 'Latitude', 'lon': 'Longitude'})\n",
    "        bed_2 = get_basal_layer_wgs84(stac_item_2, preloaded_layer=layer_2).rename({'lat': 'Latitude', 'lon': 'Longitude'})\n",
    "\n",
    "        bed_1 = xopr.geometry.project_dataset(bed_1, \"EPSG:3031\")\n",
    "        bed_2 = xopr.geometry.project_dataset(bed_2, \"EPSG:3031\")\n",
    "\n",
    "        x, y = intersection_geometry.coords[0]\n",
    "\n",
    "        dist_1 = np.sqrt((bed_1['x'] - x)**2 + (bed_1['y'] - y)**2)\n",
    "        dist_2 = np.sqrt((bed_2['x'] - x)**2 + (bed_2['y'] - y)**2)\n",
    "\n",
    "        min_idx_1 = dist_1.argmin().item()\n",
    "        min_idx_2 = dist_2.argmin().item()\n",
    "\n",
    "        dist_between_pts = np.sqrt((bed_1['x'][min_idx_1] - bed_2['x'][min_idx_2])**2 + (bed_1['y'][min_idx_1] - bed_2['y'][min_idx_2])**2)\n",
    "\n",
    "        elev_1 = bed_1['wgs84'][min_idx_1].item()\n",
    "        elev_2 = bed_2['wgs84'][min_idx_2].item()\n",
    "\n",
    "        return elev_1, elev_2, dist_between_pts\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_crossover_error: {e}\")\n",
    "        return None, None, None  # Return sentinel values on error\n",
    "\n",
    "def compute_crossover_error(stac_item_1, stac_item_2, intersection_geometry, preloaded_layer_1=None, preloaded_layer_2=None):\n",
    "    \"\"\"Wrapper that handles delayed objects properly\"\"\"\n",
    "    # These will be delayed objects or None\n",
    "    return compute_crossover_error_impl(stac_item_1, stac_item_2, intersection_geometry, preloaded_layer_1, preloaded_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0326cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_db_layers = {}\n",
    "future_results = {}\n",
    "for idx, row in intersections.iterrows():\n",
    "    stac_item_1 = stac_items_df.loc[row['id_1']].to_dict()\n",
    "    stac_item_2 = stac_items_df.loc[row['id_2']].to_dict()\n",
    "    stac_item_1['id'] = row['id_1']\n",
    "    stac_item_2['id'] = row['id_2']\n",
    "\n",
    "    # Fetch the layers from the database if available\n",
    "    db_key_1 = (row['collection_1'], row['opr:date_1'], row['opr:flight_1'])\n",
    "    db_key_2 = (row['collection_2'], row['opr:date_2'], row['opr:flight_2'])\n",
    "    if db_key_1 not in future_db_layers:\n",
    "        future_db_layers[db_key_1] = safe_get_layers_db(stac_item_1)\n",
    "    if db_key_2 not in future_db_layers:\n",
    "        future_db_layers[db_key_2] = safe_get_layers_db(stac_item_2)\n",
    "\n",
    "    # Create delayed task but DON'T compute yet\n",
    "    r = compute_crossover_error(\n",
    "        stac_item_1, stac_item_2, row.intersection_geometry,\n",
    "        preloaded_layer_1=future_db_layers.get(db_key_1),\n",
    "        preloaded_layer_2=future_db_layers.get(db_key_2)\n",
    "    )\n",
    "    future_results[idx] = r  # Store the delayed object, not the computed result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc54f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all delayed tasks at once\n",
    "from dask import compute\n",
    "\n",
    "# Compute all results in parallel\n",
    "results = compute(*future_results.values())\n",
    "\n",
    "# Process the results\n",
    "for idx, result in zip(future_results.keys(), results):\n",
    "    try:\n",
    "        elev_1, elev_2, dist_between_pts = result\n",
    "        if elev_1 is not None and elev_2 is not None:  # Skip failed computations\n",
    "            intersections.at[idx, 'wgs84_1'] = elev_1\n",
    "            intersections.at[idx, 'wgs84_2'] = elev_2\n",
    "            intersections.at[idx, 'layer_pt_distance'] = dist_between_pts\n",
    "        else:\n",
    "            print(f\"Skipping intersection {idx} due to computation error\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing intersection {idx}: {repr(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections['elev_diff'] = np.abs(intersections['wgs84_1'] - intersections['wgs84_2'])\n",
    "# Set elev_diff to NaN where layer_pt_distance is large\n",
    "intersections.loc[intersections['layer_pt_distance'] > 100, 'elev_diff'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_success = intersections.dropna().reset_index(drop=True)\n",
    "intersections_success = intersections_success.sort_values(by='id_1')\n",
    "intersections_success['idx'] = intersections_success.index\n",
    "hover_tooltips = [\n",
    "    (\"Index\", \"@idx\"),\n",
    "    (\"Collection 1\", \"@collection_1\"),\n",
    "    (\"Collection 2\", \"@collection_2\"),\n",
    "    (\"Difference\", \"@elev_diff{0.00} m\"),\n",
    "]\n",
    "\n",
    "vlim = intersections_success['elev_diff'].abs().quantile(0.9)\n",
    "\n",
    "hv_int = intersections_success.hvplot(color='elev_diff', hover_cols=['idx', 'collection_1', 'collection_2', 'elev_diff'], hover_tooltips=hover_tooltips, clim=(0, vlim))\n",
    "hv_int = hv_int.opts(scalebar=True)\n",
    "(features * region_hv * flight_lines * hv_int).opts(frame_width=600, aspect='equal', active_tools=['pan', 'wheel_zoom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222fc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx = 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intersection details\n",
    "intersect = intersections_success.loc[selected_idx]\n",
    "stac_1 = stac_items_df.loc[intersect['id_1']].to_dict()\n",
    "stac_2 = stac_items_df.loc[intersect['id_2']].to_dict()\n",
    "\n",
    "# Load frames\n",
    "frame_1 = opr.load_frame(stac_1)\n",
    "frame_1 = xopr.radar_util.add_along_track(frame_1)\n",
    "frame_1 = xopr.radar_util.interpolate_to_vertical_grid(frame_1, vertical_coordinate='wgs84')\n",
    "frame_2 = opr.load_frame(stac_2)\n",
    "frame_2 = xopr.radar_util.add_along_track(frame_2)\n",
    "frame_2 = xopr.radar_util.interpolate_to_vertical_grid(frame_2, vertical_coordinate='wgs84')\n",
    "\n",
    "# Project to EPSG:3031 and find closest points to intersection\n",
    "x_int, y_int = intersect.intersection_geometry.coords[0]\n",
    "frame_1_proj = xopr.geometry.project_dataset(frame_1, \"EPSG:3031\")\n",
    "frame_2_proj = xopr.geometry.project_dataset(frame_2, \"EPSG:3031\")\n",
    "\n",
    "# Find indices closest to intersection\n",
    "dist_1 = np.sqrt((frame_1_proj['x'] - x_int)**2 + (frame_1_proj['y'] - y_int)**2)\n",
    "dist_2 = np.sqrt((frame_2_proj['x'] - x_int)**2 + (frame_2_proj['y'] - y_int)**2)\n",
    "idx_1 = dist_1.argmin().item()\n",
    "idx_2 = dist_2.argmin().item()\n",
    "\n",
    "print(f\"Frame 1: {intersect['id_1']} from {intersect['collection_1']}\")\n",
    "print(f\"Frame 2: {intersect['id_2']} from {intersect['collection_2']}\")\n",
    "print(f\"Intersection at index {idx_1} (frame 1) and {idx_2} (frame 2)\")\n",
    "print(f\"Bed elevation difference: {intersect['elev_diff']:.2f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layers_to_frame(frame):\n",
    "    speed_in_ice = scipy.constants.c / np.sqrt(3.15)  # Approximate speed of light in ice (m/s)\n",
    "\n",
    "    layers = opr.get_layers(frame)\n",
    "    if len(layers) == 0:\n",
    "        print(f\"No layers found\")\n",
    "        return frame\n",
    "    \n",
    "    has_surface = False\n",
    "\n",
    "    for layer_idx in layers:\n",
    "        frame[f'layer_{layer_idx}_twtt'] = layers[layer_idx]['twtt'].interp(coords={'slow_time': frame['slow_time']})\n",
    "\n",
    "        if layer_idx == 1:\n",
    "            has_surface = True\n",
    "            frame[f'layer_{layer_idx}_range'] = frame['layer_1_twtt'] * (scipy.constants.c / 2)\n",
    "            frame[f'layer_{layer_idx}_elevation'] = frame['Elevation'] - frame[f'layer_1_range']\n",
    "        elif has_surface:\n",
    "            twtt_from_surface = frame[f'layer_{layer_idx}_twtt'] - frame['layer_1_twtt']\n",
    "            frame[f'layer_{layer_idx}_range'] = (twtt_from_surface * (speed_in_ice / 2)) + frame['layer_1_range']\n",
    "            frame[f'layer_{layer_idx}_elevation'] = frame['Elevation'] - frame[f'layer_{layer_idx}_range']\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Load layers for both frames\n",
    "frame_1 = add_layers_to_frame(frame_1)\n",
    "frame_2 = add_layers_to_frame(frame_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562zxg8hdzl",
   "metadata": {},
   "outputs": [],
   "source": [
    "clb_min_pct, clb_max_pct = 30, 97\n",
    "\n",
    "# Plot radargrams in elevation coordinates with layers\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# Frame 1 radargram in elevation\n",
    "pwr_1_elev = 10*np.log10(np.abs(frame_1.Data))\n",
    "vmax_1 = np.percentile(pwr_1_elev, clb_max_pct)\n",
    "vmin_1 = np.percentile(pwr_1_elev, clb_min_pct)\n",
    "pwr_1_elev.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax1, vmin=vmin_1, vmax=vmax_1)\n",
    "ax1.axvline(frame_1.along_track[idx_1].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers using elevation data\n",
    "frame_1['layer_1_elevation'].plot(ax=ax1, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface')\n",
    "frame_1['layer_2_elevation'].plot(ax=ax1, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed')\n",
    "\n",
    "ax1.set_title(f\"{intersect['collection_1']} - {intersect['id_1']} (Elevation view)\")\n",
    "ax1.set_ylabel('Elevation (m)')\n",
    "ax1.legend()\n",
    "\n",
    "# Frame 2 radargram in elevation\n",
    "pwr_2_elev = 10*np.log10(np.abs(frame_2.Data))\n",
    "vmax_2 = np.percentile(pwr_2_elev, clb_max_pct)\n",
    "vmin_2 = np.percentile(pwr_2_elev, clb_min_pct)\n",
    "pwr_2_elev.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax2, vmin=vmin_2, vmax=vmax_2)\n",
    "ax2.axvline(frame_2.along_track[idx_2].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers using elevation data\n",
    "frame_2['layer_1_elevation'].plot(ax=ax2, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface')\n",
    "frame_2['layer_2_elevation'].plot(ax=ax2, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed')\n",
    "\n",
    "ax2.set_title(f\"{intersect['collection_2']} - {intersect['id_2']} (Elevation view)\")\n",
    "ax2.set_xlabel('Along track distance (m)')\n",
    "ax2.set_ylabel('Elevation (m)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(f\"Radargrams in elevation coordinates - Bed elev diff: {intersect['elev_diff']:.2f} m\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sucnjg98mmc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed elevation plots around crossover\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "window_size = 300  # Number of traces on each side of intersection\n",
    "elev_window = np.maximum(intersect['elev_diff']*2.5, 100)  # Elevation window in meters around bed\n",
    "\n",
    "# Frame 1 zoomed\n",
    "idx_start_1 = max(0, idx_1 - window_size)\n",
    "idx_end_1 = min(len(frame_1.slow_time), idx_1 + window_size)\n",
    "bed_elev_1 = frame_1['layer_2_elevation'].isel(slow_time=idx_1).values\n",
    "elev_min_1 = bed_elev_1 - elev_window/2\n",
    "elev_max_1 = bed_elev_1 + elev_window/2\n",
    "\n",
    "pwr_1_zoom = frame_1.Data.isel(slow_time=slice(idx_start_1, idx_end_1))\n",
    "pwr_1_zoom_db = 10*np.log10(np.abs(pwr_1_zoom))\n",
    "pwr_1_zoom_db.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax1, vmin=vmin_1, vmax=vmax_1)\n",
    "ax1.axvline(frame_1.along_track[idx_1].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers\n",
    "layer_1_zoom = frame_1['layer_1_elevation'].isel(slow_time=slice(idx_start_1, idx_end_1))\n",
    "layer_1_zoom.plot.scatter(ax=ax1, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface', s=4)\n",
    "layer_2_zoom = frame_1['layer_2_elevation'].isel(slow_time=slice(idx_start_1, idx_end_1))\n",
    "layer_2_zoom.plot.scatter(ax=ax1, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed', s=4)\n",
    "\n",
    "ax1.set_ylim(elev_min_1, elev_max_1)\n",
    "ax1.set_title(f\"{intersect['collection_1']} - Zoomed (Bed: {intersect['wgs84_1']:.1f} m)\")\n",
    "ax1.set_ylabel('Elevation (m)')\n",
    "ax1.legend()\n",
    "\n",
    "# Frame 2 zoomed\n",
    "idx_start_2 = max(0, idx_2 - window_size)\n",
    "idx_end_2 = min(len(frame_2.slow_time), idx_2 + window_size)\n",
    "bed_elev_2 = frame_2['layer_2_elevation'].isel(slow_time=idx_2).values\n",
    "elev_min_2 = bed_elev_2 - elev_window/2\n",
    "elev_max_2 = bed_elev_2 + elev_window/2\n",
    "\n",
    "pwr_2_zoom = frame_2.Data.isel(slow_time=slice(idx_start_2, idx_end_2))\n",
    "pwr_2_zoom_db = 10*np.log10(np.abs(pwr_2_zoom))\n",
    "pwr_2_zoom_db.plot.imshow(x='along_track', y='wgs84', cmap='gray', ax=ax2, vmin=vmin_2, vmax=vmax_2)\n",
    "ax2.axvline(frame_2.along_track[idx_2].values, color='red', linestyle='--', linewidth=2, label='Crossover')\n",
    "\n",
    "# Plot layers\n",
    "layer_1_zoom = frame_2['layer_1_elevation'].isel(slow_time=slice(idx_start_2, idx_end_2))\n",
    "layer_1_zoom.plot.scatter(ax=ax2, x='along_track', linestyle=':', color='tab:blue', linewidth=2, label='Surface', s=4)\n",
    "layer_2_zoom = frame_2['layer_2_elevation'].isel(slow_time=slice(idx_start_2, idx_end_2))\n",
    "layer_2_zoom.plot.scatter(ax=ax2, x='along_track', linestyle=':', color='tab:orange', linewidth=2, label='Bed', s=4)\n",
    "\n",
    "ax2.set_ylim(elev_min_2, elev_max_2)\n",
    "ax2.set_title(f\"{intersect['collection_2']} - Zoomed (Bed: {intersect['wgs84_2']:.1f} m)\")\n",
    "ax2.set_xlabel('Along track distance (m)')\n",
    "ax2.set_ylabel('Elevation (m)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle(f\"Elevation crossover comparison - Bed difference: {intersect['elev_diff']:.2f} m\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864be39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
