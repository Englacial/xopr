{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7e7209",
   "metadata": {},
   "source": [
    "---\n",
    "title: Crossover analysis\n",
    "description: Using xOPR to automatically find radar crossovers\n",
    "date: 2025-09-09\n",
    "---\n",
    "\n",
    "In this notebook, we demonstratate how to automatically find and analyze radar crossovers, both within and between campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import scipy.constants\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xopr.opr_access\n",
    "import xopr.geometry\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "hvplot.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e44ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful projections\n",
    "epsg_3031 = ccrs.Stereographic(central_latitude=-90, true_scale_latitude=-71)\n",
    "latlng = ccrs.PlateCarree()\n",
    "features = gf.ocean.options(scale='50m').opts(projection=epsg_3031) * gf.coastline.options(scale='50m').opts(projection=epsg_3031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish an OPR session\n",
    "# You'll probably want to set a cache directory if you're running this locally to speed\n",
    "# up subsequent requests. You can do other things like customize the STAC API endpoint,\n",
    "# but you shouldn't need to do that for most use cases.\n",
    "opr = xopr.opr_access.OPRConnection(cache_dir=\"radar_cache\")\n",
    "\n",
    "# Or you can open a connection without a cache directory (for example, if you're parallelizing\n",
    "# this on a cloud cluster without persistent storage).\n",
    "#opr = xopr.OPRConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252449c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = xopr.geometry.get_antarctic_regions(name='David', merge_regions=True, simplify_tolerance=100)\n",
    "\n",
    "# Create a GeoViews object for the selected region\n",
    "region_gv = gv.Polygons(region, crs=latlng).opts(\n",
    "    color='green',\n",
    "    line_color='black',\n",
    "    fill_alpha=0.5,\n",
    "    projection=epsg_3031,\n",
    ")\n",
    "features * region_gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be63534",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_items = opr.query_frames(geometry=region)\n",
    "\n",
    "# This feels sloppy, but there would be an easy fix if we just natively returned a GeoDataFrame from query_frames.\n",
    "# It seems like it would generally be an improvement over a list and GeoPandas is already a dependency.\n",
    "\n",
    "stac_items_df = gpd.GeoDataFrame(stac_items)\n",
    "stac_items_df = stac_items_df.set_index('id')\n",
    "stac_items_df = stac_items_df.set_geometry(stac_items_df['geometry'].apply(shapely.geometry.shape))\n",
    "stac_items_df.crs = \"EPSG:4326\"\n",
    "stac_items_df = stac_items_df.to_crs(epsg_3031)\n",
    "\n",
    "print(f\"Found {len(stac_items)} frames across {stac_items_df['collection'].nunique()} collections:\")\n",
    "\n",
    "stac_items_df.groupby('collection').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(opr.query_frames(seasons='2013_Antarctica_P3', flight_ids='20131120_01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_items[0]['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO TODO TODO\n",
    "\n",
    "stac_item = stac_items[0]\n",
    "\n",
    "layers = opr.get_layers_db(stac_item)\n",
    "layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_lines = stac_items_df.hvplot(by='collection')\n",
    "(features * region_gv * flight_lines).opts(projection=epsg_3031, frame_width=600, aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fa14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitely room for improvement here, but the geopandas spatial join works pretty nicely for finding intersections between frames.\n",
    "# Couple thoughts:\n",
    "# 1. We might want to include a helper function for this\n",
    "# 2. This will not find self-intersections within a single frame.\n",
    "\n",
    "tmp_df = stac_items_df.reset_index()\n",
    "tmp_df['geom'] = tmp_df.geometry\n",
    "intersections = gpd.sjoin(tmp_df, tmp_df, how='inner', predicate='intersects', lsuffix='1', rsuffix='2')\n",
    "intersections = intersections[intersections['id_1'] != intersections['id_2']]\n",
    "intersections['intersection_geometry'] = intersections.apply(lambda row: row['geom_1'].intersection(row['geom_2']), axis=1)\n",
    "intersections.set_geometry('intersection_geometry', inplace=True, crs=stac_items_df.crs)\n",
    "intersections = intersections.drop_duplicates(subset=['intersection_geometry'])\n",
    "intersections = intersections.explode(index_parts=True).reset_index(drop=True)\n",
    "print(f\"Found {len(intersections)} crossover points between flight lines.\")\n",
    "(features * region_gv * flight_lines * intersections.hvplot(label='Intersection Points', color='purple')).opts(frame_width=600, aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ad78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result of this is a GeoDataFrame where every column from the intersecting frames is preserved, with suffixes _1 and _2 to distinguish them.\n",
    "intersections.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f40952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This surfaced a lot of issues with layers...\n",
    "# 1. It's annoying that you need to load a frame in order to get the layers for that flight. We should probably have a way to get layers directly from a STAC item.\n",
    "# 1a. This work-around is OK for loading layer files, but it doesn't help with loading database layers. The databse layers include timing but not position information, so additional queries would be needed to get the position.\n",
    "# 2. We should probably make both get_layers_files and get_layers_db return the same dataset structure.\n",
    "# 3. Caching is a bit awkard here because get_layers_db will load the entire flight line.\n",
    "# 4. The functionality to trim layers to the time range of the frame is broken in some cases because slow_time is sometimes returned as a float64 instead of a datetime64[ns]. We should fix this.\n",
    "\n",
    "layer_cache = {}\n",
    "\n",
    "def get_layers_stac_item(stac_item):\n",
    "    ds_fake = xr.Dataset()\n",
    "    ds_fake.attrs['season'] = stac_item['collection']\n",
    "    ds_fake.attrs['segment'] = f\"{stac_item['properties'].get('opr:date')}_{stac_item['properties'].get('opr:flight'):02d}\"\n",
    "\n",
    "    if (ds_fake.attrs['season'], ds_fake.attrs['segment']) in layer_cache:\n",
    "        #print(f\"Using cached layers for {ds_fake.attrs['season']} segment {ds_fake.attrs['segment']}...\")\n",
    "        return layer_cache[(ds_fake.attrs['season'], ds_fake.attrs['segment'])]\n",
    "\n",
    "    #print(f\"Loading layers for {ds_fake.attrs['season']} segment {ds_fake.attrs['segment']}...\")\n",
    "\n",
    "    layers = None\n",
    "    layers = opr.get_layers_files(ds_fake)\n",
    "\n",
    "    layer_cache[(ds_fake.attrs['season'], ds_fake.attrs['segment'])] = layers\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94361c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_cache = {}\n",
    "\n",
    "def get_basal_layer(stac_item):\n",
    "    flight_id = f\"{stac_item['properties'].get('opr:date')}_{stac_item['properties'].get('opr:flight'):02d}\"\n",
    "    if (stac_item['collection'], flight_id) in layer_cache:\n",
    "        #print(f\"Using cached basal layer for {flight_id}\")\n",
    "        return layer_cache[(stac_item['collection'], flight_id)]\n",
    "\n",
    "    try:\n",
    "        layers = opr.get_layers_files(stac_item)\n",
    "        basal_layer = layers[2]\n",
    "        #print(f\"Loaded basal layer from files for {flight_id}\")\n",
    "        layer_cache[(stac_item['collection'], flight_id)] = basal_layer\n",
    "        return basal_layer\n",
    "    except Exception as e:\n",
    "        layers = opr.get_layers_db(stac_item)\n",
    "        basal_layer = layers[2]\n",
    "        #print(f\"Loaded basal layer from database for {flight_id}\")\n",
    "        layer_cache[(stac_item['collection'], flight_id)] = basal_layer\n",
    "        return basal_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41877704",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections['elev_1'] = np.nan\n",
    "intersections['elev_2'] = np.nan\n",
    "\n",
    "idx = 0\n",
    "row = intersections.iloc[idx]\n",
    "\n",
    "for idx, row in tqdm(intersections.iterrows(), total=len(intersections)):\n",
    "    stac_item_1 = stac_items_df.loc[row['id_1']].to_dict()\n",
    "    stac_item_2 = stac_items_df.loc[row['id_2']].to_dict()\n",
    "\n",
    "    try:\n",
    "        bed_1 = get_basal_layer(stac_item_1).rename({'lat': 'Latitude', 'lon': 'Longitude'})\n",
    "        bed_2 = get_basal_layer(stac_item_2).rename({'lat': 'Latitude', 'lon': 'Longitude'})\n",
    "\n",
    "        bed_1 = xopr.geometry.project_dataset(bed_1, \"EPSG:3031\")\n",
    "        bed_2 = xopr.geometry.project_dataset(bed_2, \"EPSG:3031\")\n",
    "\n",
    "        x, y = row.intersection_geometry.coords[0]\n",
    "\n",
    "        dist_1 = np.sqrt((bed_1['x'] - x)**2 + (bed_1['y'] - y)**2)\n",
    "        dist_2 = np.sqrt((bed_2['x'] - x)**2 + (bed_2['y'] - y)**2)\n",
    "\n",
    "        elev_1 = bed_1['elev'][(dist_1 == dist_1.min())].values[0].item()\n",
    "        elev_2 = bed_2['elev'][(dist_2 == dist_2.min())].values[0].item()\n",
    "\n",
    "        intersections.at[idx, 'elev_1'] = elev_1\n",
    "        intersections.at[idx, 'elev_2'] = elev_2\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing intersection {idx} between {row['id_1']} and {row['id_2']}: {repr(e)}\")\n",
    "        #traceback.print_exc()\n",
    "\n",
    "intersections['elev_diff'] = intersections['elev_1'] - intersections['elev_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe the fairly few intersections still in the set are due to the older flights not having layer files (or not having layer files with bed picks).\n",
    "# We probably just need to get db layer data working for those.\n",
    "\n",
    "intersections[~intersections['elev_diff'].isna()][['id_1', 'collection_1', 'id_2', 'collection_2', 'elev_1', 'elev_2', 'elev_diff']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersections_success = intersections.dropna()\n",
    "intersections_success['idx'] = intersections_success.index\n",
    "hover_tooltips = [\n",
    "    (\"Index\", \"@idx\"),\n",
    "    (\"Collection 1\", \"@collection_1\"),\n",
    "    (\"Collection 2\", \"@collection_2\"),\n",
    "    (\"Difference\", \"@elev_diff{0.00} m\"),\n",
    "]\n",
    "hv_int = intersections_success.hvplot(color='elev_diff', cmap='coolwarm_r', hover_cols=['idx', 'collection_1', 'collection_2', 'elev_diff'], hover_tooltips=hover_tooltips)\n",
    "hv_int = hv_int.opts(scalebar=True)\n",
    "(features * region_gv * flight_lines * hv_int).opts(frame_width=600, aspect='equal', active_tools=['pan', 'wheel_zoom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222fc910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
